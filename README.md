# DTSC Portfolio 
[About me](about me) | [Portfolio](Portfolio) | [Blog](Blog)


---


### About me
Hi, my name is Parnika and I am a Freshman the the University of North Caroliona at Charlotte. I am a double major in Math and Data Science, math has always been my favorite subject since elemetary schools! I'm excited to continue learning about the ins and out of Data Science and how it connects to the world around us. Some of my hobbies include listening to music, hangingout with friends and doing anything fun.

### Protfolio
- Project 1
- Project 2

### Blog

#### Why is learning data science in social and interdiciplinary contexts matters
To answer this question we first need to know what is data science, it is the study of fields that use scientific methods, process, algorithms and systems to extract knowledge and insights from structured and unstructured data. It combine statistics, computer science, and domain expertise to solve problems and drive decisions. While it may not seem like it data science is used for many things in our day to day life, such as our FYP (for you page) in instagram, tiktok or even the advertisments we see. So why should we modle social topics and people, well for starters these are things that make up our society on a daily so its good to know some information on them. It helps us gain objective insights and helps optimize resource allocation for social good, these data driven solutions help solve complex social problems and help make more infomred decision. While solving these problems are important it is also important to take into account the information we are taking, we need to make sure that the peoples information is not put at jepordy, we can't let biases determine the conclusion of data along with not using overly sensetive imformation about individuals. In this course I hope ot learn more about how to create algorithims to make models along with just learning anything new! 


#### Three major questions
Ethically ambiguous data modeling refers to the development and use of data models where ethical implications, however there are not immediately clear-cut. These models often operate in the grey areas where harm is possible, even when best practices are followed. I think ethical ambiguity can arise from various factors, including the use of incomplete or biased data, the potential for proxy variables, or a misalignment between technical goals and broader social outcomes. A model might perform well in predicting outcomes but still perpetuate unfairness or discrimination, making it ethically ambiguous. To summarize what can be ethically ambiguous can be anything. When rules become absent and the answer goes into the human hands it is important to always have a standard of what we want.

To address the challenges posed by ethically ambiguous data modeling, several best practices can be implemented. First, data auditing helps identify potential biases and errors in the data used to train the model, this practice helps show if the model has any hidden potential that could throw off the algorithm when faced with data that was not in the training set. Second, stakeholder engagement involves consulting with diverse groups to gather different perspectives and assess the potential impact of the model. Being able to do this allows the data scientist to gain more perspectives on their project and consider things that they would not have thought of. Finally, transparency and model interpretability enable a deeper understanding of the model's decision-making process, allowing for the identification of potential ethical concerns.

A real-world example of an ethically ambiguous model could be a predictive policing algorithm, or the court algorithm to find repeat offenders, like the ones we talked about in class. This algorithm may be designed to predict crime hotspots based on historical data. While it might effectively allocate police resources, it could also lead to over-policing in certain communities. The historical data used to train the model may reflect existing biases in law enforcement, which means the model could perpetuate these biases, leading to disproportionate stops and arrests in specific neighborhoods, where there could be more minorities. This is a case where technical effectiveness clashes with ethical considerations. This shows that the system is working because the officers are making arrests but is it because there is actually crime there or just because there are officers looking for anything that could be a crime.


